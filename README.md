# Multi-modal Large Language Model Collection ðŸ¦•
This is a curated list of Multi-modal Large Language Models (MLLM), Multimodal Benchmarks (MMB), Multimodal Instruction Tuning (MMIT), Multimodal In-context Learning (MMIL), Foundation Models (*e.g.*, CLIP families) (FM), and the most popular Parameter-Efficient Tuning methods.

## ðŸ“’Table of Contents
- [Multi-modal Large Language Models (MLLM)](#multimodal-large-language-models)
- [Multimodal Benchmarks (MMB)](#multimodal-benchmarks)
- [Multimodal Instruction Tuning (MMIT)](#multimodal-instruction-tuning)
- [Multimodal In-context Learning (MMIL)](#multimodal-in-context-learning)
- [Foundation Models (FM)](#foundation-models)
- [Parameter-Efficient Tuning (PET)](#parameter-efficient-tuning)

> ### Multi-modal Large Language Models (MLLM)

* **LAMM: Language-Assisted Multi-Modal Instruction-Tuning Dataset, Framework, and Benchmark** [Arxiv 2023] [[paper](https://arxiv.org/pdf/2306.06687.pdf)]<br>
<sup>1</sup>Shanghai AI Lab, <sup>2</sup>Beihang University, <sup>3</sup>The Chinese University of Hong Kong (Shenzhen), <sup>4</sup>Fudan University, <sup>5</sup>Dalian University of Technology, <sup>6</sup>The University of Sydney<br>

> ### Foundation Models (FM)
* **LLaMA: Open and Efficient Foundation Language Models** [Arxiv 2023] [[paper](https://arxiv.org/pdf/2302.13971v1.pdf)] [[Github Repo](https://github.com/facebookresearch/llama)]<br>



> ### Parameter-Efficient Tuning (PET)
* **PEFT: Parameter-Efficient Fine-Tuning** [HuggingFace ðŸ¤—] [[Home Page](https://huggingface.co/docs/peft/index)] [[Github Repo](https://github.com/huggingface/peft)]<br>
PEFT, or Parameter-Efficient Fine-Tuning (PEFT), is a library for efficiently adapting pre-trained language models (PLMs) to various downstream applications without fine-tuning all the modelâ€™s parameters. <br>

